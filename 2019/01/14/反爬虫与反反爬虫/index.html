<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="python,sergiojune,记录，算法"><title>反爬虫与反反爬虫 | sergiojune | 梦开始的地方</title><link rel="stylesheet" type="text/css" href="//fonts.neworld.org/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">反爬虫与反反爬虫</h1><a id="logo" href="/.">sergiojune | 梦开始的地方</a><p class="description">路在，人就在</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Arama"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">反爬虫与反反爬虫</h1><div class="post-meta"><a href="/2019/01/14/反爬虫与反反爬虫/#comments" class="comment-count"><i data-disqus-identifier="2019/01/14/反爬虫与反反爬虫/" class="disqus-comment-count"></i>留言</a><p><span class="date">Jan 14, 2019</span><span><a href="/categories/python/" class="category">python</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><section class="96edit" label="Powered by bj.96weixin.com" style="font-size:16px;"><section class="editor"><section editor="bj.96weixin.com" style="margin:0 auto;padding:0;box-sizing:border-box"><section class="yead_bgc wx-bg" style="border-style: solid; -webkit-border-image: url(&quot;https://mmbiz.qpic.cn/mmbiz_png/v4vz52CcB13JzTTXXg3mC439fK28gxRK85c5jJicI6ia4ibEOx5DTicoiciamOZc6hcaLFy9S1AfhJzm8kUAHJnv4jtQ/0&quot;) 15 5 5 fill stretch; color: rgb(51, 51, 51); border-width: 10px 4px 4px; padding: 0px; box-sizing: border-box; background-color: rgb(51, 184, 108);"><section style="width: 100%; font-size: 14px; margin: 0px; line-height: 30px; padding: 0px 5px; box-sizing: border-box;" data-width="100%"><p style="padding:0;margin:0;text-align:justify">喜欢爬虫的伙伴都知道，在爬网站的内容的时候并不是一爬就可以了，有时候就会遇到一些网站的反爬虫，折回让你爬不到数据，给你返回一些404，403或者500的状态码，这有时候会让人苦不堪言，就如我昨天发的爬网易云音乐评论，在你爬的数据较多时，网站认为你是一个机器，就不让你爬了，网易云就给我返回了一个<strong>{“code”:-460,”msg”:”Cheating”}，</strong>你不看下他的返回内容还不知道自己被反爬虫，不过不用担心，既然网页有反爬虫，可我们也有反反爬虫，今天就给大家说说反爬虫与反反爬虫。</p></section></section></section><p><br></p></section><section class="editor"><section style="border: 0px; margin: 0px auto; padding: 0px; text-align: center; box-sizing: border-box;"><section style="padding: 5px 10px; line-height: 30px; text-align: center; font-size: 14px; border: 3px solid rgb(51, 184, 108); display: inline-block; box-sizing: border-box; background-color: rgb(255, 255, 255);"><section style="padding: 0px; color: rgb(255, 255, 255); height: 30px; width: 30px; line-height: 30px; text-align: center; font-size: 14px; display: inline-block; border-radius: 100%; box-sizing: border-box; background-color: rgb(51, 184, 108);"><p>1</p></section><section style="padding: 0px 0px 0px 10px; color: rgb(51, 184, 108); line-height: 30px; text-align: center; font-size: 14px; border: 0px; display: inline-block; box-sizing: border-box;"><p>网页的反爬虫</p></section></section><section style="padding: 0px; margin: 0px auto; color: rgb(255, 255, 255); width: 0px; height: 0.4rem; text-align: center; border-width: 0.4rem 0.6rem 0px; border-style: solid; border-color: rgb(51, 184, 108) rgb(255, 255, 255) rgb(255, 255, 255); box-sizing: border-box;"></section></section></section><p><br></p><p><strong>1.通过网页的请求头</strong><br></p><p>首先我们先看看网易云音乐评论的请求头<img src="http://pic.96weixin.com/upload/image2/vip/881679/1802/1802099052.png" title="1802099052.png" alt=""><strong><br></strong></p><p><br></p><p><strong>User-Agent：</strong>这个是保存用户访问该网站的浏览器的信息，我上面这个表示的是我通过window的浏览器来访问这个网站的，如果你是用python来直接请求这个网站的时候，这个的信息会带有python的字眼，所以网站管理员可以通过这个来进行反爬虫。</p><p><br></p><p><strong>Referer：</strong>当浏览器发送请求时，一般都会带上这个，这个可以让网站管理者知道我是通过哪个链接访问到这个网站的，上面就说明我是从网易云音乐的主页来访问到这个页面的，若你是用python来直接请求是，就没有访问来源，那么管理者就轻而易举地判断你是机器在操作。</p><p><br></p><p><strong><span style="color: rgb(63, 63, 63); font-family: 'microsoft yahei'; line-height: 27.2px;">authorization</span></strong>:有的网站还会有这个请求头，这个是在用户在访问该网站的时候就会分配一个id给用户，然后在后台验证该id有没有访问权限从而来进行发爬虫。<br></p><p><br></p><p><strong>2.用户访问网站的ip</strong></p><p>当你这个ip在不断地访问一个网站来获取数据时，网页后台也会判断你是一个机器。就比如我昨天爬的网易云音乐评论，我刚开始爬的一首《海阔天空》时，因为评论较少，所以我容易就得到所有数据，但是当我选择爬一首较多评论的《等你下课》时，在我爬到800多页的时候我就爬不了，这是因为你这个ip的用户在不断地访问这个网站，他已经把你视为机器，所以就爬不了，暂时把你的ip给封了。<strong><br></strong></p><p><br></p><section class="editor"><section style="border: 0px; margin: 0px auto; padding: 0px; text-align: center; box-sizing: border-box;"><section style="padding: 5px 10px; line-height: 30px; text-align: center; font-size: 14px; border: 3px solid rgb(51, 184, 108); display: inline-block; box-sizing: border-box; background-color: rgb(255, 255, 255);"><section style="padding: 0px; color: rgb(255, 255, 255); height: 30px; width: 30px; line-height: 30px; text-align: center; font-size: 14px; display: inline-block; border-radius: 100%; box-sizing: border-box; background-color: rgb(51, 184, 108);"><p>2</p></section><section style="padding: 0px 0px 0px 10px; color: rgb(51, 184, 108); line-height: 30px; text-align: center; font-size: 14px; border: 0px; display: inline-block; box-sizing: border-box;"><p>我们的反反爬虫</p></section></section><section style="padding: 0px; margin: 0px auto; color: rgb(255, 255, 255); width: 0px; height: 0.4rem; text-align: center; border-width: 0.4rem 0.6rem 0px; border-style: solid; border-color: rgb(51, 184, 108) rgb(255, 255, 255) rgb(255, 255, 255); box-sizing: border-box;"></section></section></section><p><br></p><p><strong>1.添加请求头</strong></p><p>既然在请求网页的时候需要请求头，那么我们只需要在post或者get的时候把我们的请求头加上就可以了，怎样加？可以使用<strong>requests</strong>库来添加，在post，get或者其他方法是加上<strong>headers</strong>参数就可以了，而请求头不需要复制所有的信息，只需要上面的三个之中一个就可以，至于哪个自己判断，或者直接添加所有也可以，这样我们就可以继续爬了。</p><p><br></p><p><strong>2.使用代理ip</strong></p><p>若是网站把你的ip给封了，你添加什么的请求头也都没有用了，那我们就只有等他解封我们才可以继续爬吗？我可以十分自信告诉你：<strong>不需要</strong>，我们可以使用代理ip来继续爬，我们可以爬取网络上的免费ip来爬，至于免费的代理ip质量怎样你们应该知道，有必要可以买些不免费的，这样好点，我们平时的练习用免费的代理ip就可以了，可以自己爬取一些免费代理ip建成ip池，然后爬的时候就把ip随机取出来，我偷偷告诉你：小编明天的文章就是教你怎样搭建自己的代理ip池。</p><p><br></p><section class="editor"><section style="border: 0px none; box-sizing: border-box;"><section style="margin: 10px 0px; padding: 0px; text-align: center; font-family: 微软雅黑; box-sizing: border-box;"><section class="96wx-bdlc 96wx-bdrc" style="margin: 0px; padding: 0px; height: 24px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(245, 189, 209); border-left-width: 1px; border-left-style: solid; border-left-color: rgb(245, 189, 209); box-sizing: border-box;"></section><section class="96wx-bdbc" style="margin-top: -12px; margin-bottom: -12px; padding: 0px; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(245, 189, 209); box-sizing: border-box;"></section><section style="margin: 0px; padding: 0px; display: inline-block; box-sizing: border-box;"><section class="96wx-bdrc" style="margin: 0px; padding: 0px; border-right-width: 15px; border-right-style: solid; border-right-color: rgb(245, 189, 209); border-top-width: 12px; border-top-style: solid; border-top-color: transparent; border-bottom-width: 12px; border-bottom-style: solid; border-bottom-color: transparent; height: 0px; width: 0px; float: left; box-sizing: border-box;"></section><section class="96wx-bgc" style="margin: 0px; padding: 0px; height: 24px; min-width: 4em; color: rgb(255, 255, 255); line-height: 24px; float: left; box-sizing: border-box; background-color: rgb(245, 189, 209);"><span style="color:inherit; font-size:12px">END</span></section><section class="96wx-bdlc" style="margin: 0px; padding: 0px; border-left-width: 15px; border-left-style: solid; border-left-color: rgb(245, 189, 209); border-top-width: 12px; border-top-style: solid; border-top-color: transparent; height: 0px; width: 0px; float: left; border-bottom-width: 12px; border-bottom-style: solid; border-bottom-color: transparent; box-sizing: border-box;"></section></section></section></section></section><p>结束语：上面的只是个人在爬一些网站时候遇到的一些反爬虫，这只是很简单的，还有那些动态网站的反爬虫自己还没有接触，等到以后接触了，再一 一补充。最后给大家在爬虫上的建议，就是爬取速度不要太快，最好每几个就隔几秒，不要给服务器造成太大的压力，也可以在爬虫的时候选择一些访问量少点的时间段，这是对服务器好，也是对你自己好！</p><section class="editor"><p><br></p></section><p style="text-align: center;"><span style="font-size: 14px;">日常学python</span></p><p><br></p><p style="text-align: center;"><img style="border-radius: 5px; border: 1px dashed rgb(168, 164, 171); box-shadow: rgba(0, 0, 0, 0.329412) 6px 6px 5px 0px; margin-bottom: 1.4px; visibility: visible !important; width: 111.297px !important;" src="http://pic.96weixin.com/upload/image2/vip/881679/1802/1802054148.png" height="auto" border="0" alt="1802054148.png"></p><p style="text-align: center;"><span style="font-size: 14px;">一个专注于python的公众号</span></p><p><br></p></section></div><div class="tags"><a href="/tags/爬虫/">爬虫</a><a href="/tags/requestst/">requestst</a></div><div class="post-share"><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到：</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2019/01/14/教你用python登陆豆瓣并爬取影评/" class="pre">教你用python登陆豆瓣并爬取影评</a><a href="/2019/01/14/搭建自己的代理ip池/" class="next">搭建自己的代理ip池</a></div><div id="comments"><div id="disqus_thread"></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/01/14/学习用python操作mysql/">学习用python操作mysql</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/14/谈谈如何抓取ajax动态网站/">谈谈如何抓取ajax动态网站</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/14/我爬取了37000条球迷评论，知道了这场比赛的重要信息/">我爬取了37000条球迷评论，知道了这场比赛的重要信息</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/14/老司机带你用python来爬取妹子图/">老司机带你用python来爬取妹子图</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/14/教你用python登陆豆瓣并爬取影评/">教你用python登陆豆瓣并爬取影评</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/14/反爬虫与反反爬虫/">反爬虫与反反爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/14/搭建自己的代理ip池/">搭建自己的代理ip池</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/14/python爬取豆瓣电影Top250/">利用python爬取豆瓣电影Top250，并把数据放入MySQL数据库</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/14/python爬虫常用库之requests详解/">python爬虫常用库之requests详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/14/python爬虫常用库之BeautifulSoup详解/">python爬虫常用库之BeautifulSoup详解</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Fiddler/">Fiddler</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/android/">android</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/blog/">blog</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a><span class="category-list-count">17</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/python/数据库/">数据库</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/个人随想/">个人随想</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/基础/">基础</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/总结/">总结</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构/">数据结构</a><span class="category-list-count">6</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/时间复杂度/" style="font-size: 15px;">时间复杂度</a> <a href="/tags/hard/" style="font-size: 15px;">hard</a> <a href="/tags/run/" style="font-size: 15px;">run</a> <a href="/tags/坑/" style="font-size: 15px;">坑</a> <a href="/tags/栈/" style="font-size: 15px;">栈</a> <a href="/tags/单链表-冒泡排序/" style="font-size: 15px;">单链表 冒泡排序</a> <a href="/tags/单链表/" style="font-size: 15px;">单链表</a> <a href="/tags/数组/" style="font-size: 15px;">数组</a> <a href="/tags/c/" style="font-size: 15px;">c</a> <a href="/tags/胡思乱想/" style="font-size: 15px;">胡思乱想</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/requestst/" style="font-size: 15px;">requestst</a> <a href="/tags/抓包/" style="font-size: 15px;">抓包</a> <a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/requests/" style="font-size: 15px;">requests</a> <a href="/tags/正则表达式/" style="font-size: 15px;">正则表达式</a> <a href="/tags/urllib/" style="font-size: 15px;">urllib</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/11/">十一月 2017</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="https://sergiojune.com/about/" title="需要设置请联系我" target="_blank">需要设置请联系我</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Baidu Site Haritası</a> |  <a href="/atom.xml">订阅</a> |  <a href="/about/">关于</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次</p><p><span> Copyright &copy;<a href="/." rel="nofollow">sergiojune.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script><script>var disqus_shortname = 'sergiojune';
var disqus_identifier = '2019/01/14/反爬虫与反反爬虫/';
var disqus_title = '反爬虫与反反爬虫';
var disqus_url = 'http://sergiojune.com/2019/01/14/反爬虫与反反爬虫/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//sergiojune.disqus.com/count.js" async></script><script type="text/javascript" src="//sergiojune.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></body></html>